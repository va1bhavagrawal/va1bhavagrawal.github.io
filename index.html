<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Vaibhav Agrawal</title>
  <meta name="author" content="Vaibhav Agrawal">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <!-- Add Source Sans 3 (formerly Source Sans Pro) -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Source+Sans+3:ital,wght@0,300;0,400;0,500;0,600;0,700;0,800;1,300;1,400;1,500;1,600;1,700;1,800&display=swap" rel="stylesheet">
  <!-- Font Awesome CDN for icons -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha512-SnH5WK+bZxgPHs44uWIX+LLJAJ9/2PkPKZ5QiAj6Ta86w+fsb2TkcmfRyVX3pBnMFcV7oQPJkl9QevSCWr3W6A==" crossorigin="anonymous" referrerpolicy="no-referrer" />
  <link rel="stylesheet" type="text/css" href="style.css">
</head>

<body>
  <!-- ... rest of your HTML body remains the same ... -->
  <div class="container">
    <!-- Hero Section -->
    <section class="hero-section">
      <div class="hero-content">
        <div class="hero-text">
          <h1 class="name">Vaibhav Agrawal</h1>
          <p class="hero-description">
            I am a Computer Vision researcher. I am currently a Master's student at <a href="https://cvit.iiit.ac.in/">CVIT (Center for Visual Information Technology)</a>, IIIT-Hyderabad, where I am fortunate to be advised by <a href="https://ravika.github.io/">Ravi Kiran S</a> (from CVIT) and co-advised by <a href="https://cds.iisc.ac.in/faculty/venky/">Venkatesh Babu Radhakrishnan</a> (from <a href="https://val.cds.iisc.ac.in/">Vision and AI Lab, IISc Bangalore</a>). When I am not working, I am usually listening to music or playing the piano.<br><br> 
            
            I love receiving emails and messages! Hence, feel free to reach out to me in case you have any questions or suggestions about research.  
          </p>
          <div class="social-links">
            <a href="mailto:agrvaibhav19@gmail.com"><i class="fas fa-envelope"></i> Email</a>
            <a href="https://drive.google.com/file/d/1ywYaCnMGyIBCwCJhO_oFpb12eRx7yYeF/view?usp=sharing"><i class="fas fa-file-lines"></i> CV</a>
            <a href="https://scholar.google.com/citations?user=3tFzDucAAAAJ&hl=en"><i class="fas fa-graduation-cap"></i> Scholar</a>
            <a href="https://x.com/VA1BHAVAGRAWAL"><i class="fa-brands fa-x-twitter"></i> Twitter</a>
            <a href="https://github.com/va1bhavagrawal"><i class="fa-brands fa-github"></i> Github</a>
          </div>
        </div>
        <img src="images/me_.jpeg" alt="Vaibhav Agrawal" class="profile-image">
      </div>
    </section>

    <!-- Updates Section -->
    <section class="content-section">
      <h2 class="section-title">Updates</h2>
      <ul class="updates-list">
        <li><strong>Mar 2025:</strong> Our paper <em>Compass Control</em> was accepted to CVPR 2025. ðŸŽ‰ See you in Nashville!</li>
        <li><strong>Dec 2024:</strong> Presented <em>LineTR</em> at ICPR 2024 in Kolkata.</li>
      </ul>
    </section>

    <!-- Research Section -->
    <section class="content-section">
      <h2 class="section-title">Research</h2>
      <p class="research-intro">
        I am interested in computer vision, broadly. Recently I have been working on controlling generative models. I am also interested in the broader applications of generative models for various perceptual tasks in computer vision.
      </p>

      <p class="equal-contrib">* denotes equal contribution.</p>

      <div class="paper-grid">
        <!-- Compass Control Paper -->
        <div class="paper-card featured">
          <div class="paper-media">
            <img src="images/compass_control.jpg" alt="Compass Control">
          </div>
          <div class="paper-content">
            <a href="https://rishubhpar.github.io/compasscontrol/" class="paper-title">
              Compass Control: Multi-Object Orientation Control for Text-to-Image Generation
            </a>
            <div class="paper-authors">
              <a href="https://rishubhpar.github.io/">Rishubh Parihar*</a>,
              <strong>Vaibhav Agrawal*</strong>,
              <a href="https://scholar.google.com/citations?user=Hup_9BkAAAAJ&hl=en">Sachidanand VS</a>,
              <a href="https://cds.iisc.ac.in/faculty/venky/">Venkatesh Babu Radhakrishnan</a>
            </div>
            <div class="paper-venue">CVPR 2025</div>
            <div class="paper-links">
              <a href="https://rishubhpar.github.io/compasscontrol/">project page</a>
              <a href="https://arxiv.org/abs/2504.06752">arXiv</a>
            </div>
            <p class="paper-description">
              A method for multi-object orientation control in T2I generation. We learn an encoder that can map an input 3D pose to a special token to control an object, and show that the attention maps of these tokens can be constrained spatially to enable disentangled multi-object control.
            </p>
          </div>
        </div>

        <!-- LineTR Paper -->
        <div class="paper-card">
          <div class="paper-media">
            <img src="images/linetr.jpg" alt="LineTR">
          </div>
          <div class="paper-content">
            <a href="https://ihdia.iiit.ac.in/LineTR/" class="paper-title">
              LineTR: Unified Text Line Segmentation for Challenging Palm Leaf Manuscripts
            </a>
            <div class="paper-authors">
              <strong>Vaibhav Agrawal</strong>,
              Niharika Vadlamudi,
              <a href="https://scholar.google.com/citations?user=glI39rIAAAAJ&hl=en&oi=sra">Muhammad Waseem</a>,
              <a href="https://scholar.google.com/citations?user=2f_Q_K4AAAAJ&hl=en&oi=sra">Amal Joseph</a>,
              Sreenya Chitluri,
              <a href="https://ravika.github.io/">Ravi Kiran Sarvadevabhatla</a>
            </div>
            <div class="paper-venue">ICPR 2024</div>
            <div class="paper-links">
              <a href="https://ihdia.iiit.ac.in/LineTR/">project page</a>
              <a href="https://drive.google.com/file/d/1Z2nMoeyhxy_HgHTrmcT_UD2LBV-Y0FhJ/view">paper</a>
            </div>
            <p class="paper-description">
              Treating text-line detection as a segmentation problem discards various inductive priors, and hampers OOD generalization. We parametrize text-lines as geometric structures, and learn a DETR-style network to predict these parameters instead.
            </p>
          </div>
        </div>

        <!-- DATOR Paper -->
        <div class="paper-card">
          <div class="paper-media">
            <img src="images/dator.jpg" alt="Multi-Modal Object Re-ID">
          </div>
          <div class="paper-content">
            <div class="paper-title">
              Towards Global Localization Using Multi-Modal Object-Instance Re-Identification
            </div>
            <div class="paper-authors">
              <a href="https://scholar.google.com/citations?user=fiFj4AwAAAAJ&hl=en">Aneesh Chavan</a>,
              <strong>Vaibhav Agrawal*</strong>,
              Vineeth Bhat*,
              Sarthak Chittawar*,
              <a href="https://siddharthsrivastava.github.io/">Siddharth Srivastava</a>,
              <a href="https://web.iitd.ac.in/~chetan/">Chetan Arora</a>,
              <a href="https://www.iiit.ac.in/faculty/k-madhava-krishna/">K Madhava Krishna</a>
            </div>
            <div class="paper-venue">Advances in Robotics 2025</div>
            <div class="paper-links">
              <a href="https://arxiv.org/abs/2409.12002">paper</a>
            </div>
            <p class="paper-description">
              We train a multi-modal (depth + RGB) network to perform the object re-identification task. Modality dropout ensures robustness to failure of one of the modalities. We demonstrate application of the model in a downstream SLAM pipeline.
            </p>
          </div>
        </div>
      </div>
    </section>
  </div>
</body>

</html>